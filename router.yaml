# Claude Code Model Router Configuration
# This configuration routes Claude Code CLI traffic to appropriate endpoints

router:
  listen: "0.0.0.0:8787"
  original_base_url: "https://api.anthropic.com"
  openai_base_url: "https://api.openai.com"



# OpenAI configuration
openai:
  api_key_env: "OPENAI_API_KEY"
  reasoning_effort_default: "minimal"  # Cost-efficient default
  reasoning_thresholds:
    low_max: 2048      # 1-5K tokens: simple tasks (~20% of max_tokens)
    medium_max: 8192  # 5K-15K tokens: balanced tasks (~50% of max_tokens)
    # 15K+ tokens: high effort complex reasoning (up to 32K cap)

# Timeout configuration
timeouts_ms:
  connect: 5000    # 5 seconds
  read: 600000     # 10 minutes for long reasoning tasks

# Logging configuration
logging:
  level: "debug"

# Override rules for routing decisions
overrides:
  # Route plan mode requests (system prompt matches plan mode patterns) to reasoning model
  - when:
      request:
        system_regex: '\b(?:plan mode is (?:activated|triggered|on)|in plan mode)\b'
    model: "openai/gpt-5"
    
  # Route opus model requests to powerful OpenAI model
  - when:
      request:
        model_regex: "opus"
    model: "openai/gpt-5"
    
  # Route any model containing "haiku" to background model (most general first)
  # - when:
  #     request:
  #       model_regex: "haiku"
  #   model: "openai/gpt-5-mini"
    
  # Route any model containing "mini" to background model
  - when:
      request:
        model_regex: "mini"  
    model: "openai/gpt-5-mini"
  
  - when:
      request:
        model_regex: "^gpt(?:-.*)?$"  
    model: "openai/gpt-5"