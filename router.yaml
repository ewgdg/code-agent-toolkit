# Claude Code Model Router Configuration
# This configuration routes Claude Code CLI traffic to appropriate endpoints

router:
  listen: "0.0.0.0:8788"
  original_base_url: "https://api.anthropic.com"
  openai_base_url: "https://api.openai.com"



# Model mapping for OpenAI routing
mapping:
  plan_model: "openai/gpt-5"         # For plan mode requests
  background_model: "openai/gpt-5-mini"  # For haiku/background tasks

# OpenAI configuration
openai:
  api_key_env: "OPENAI_API_KEY"
  reasoning_effort_default: "minimal"  # Cost-efficient default
  include_summary: true
  reasoning_thresholds:
    low_max: 2048      # 1-5K tokens: simple tasks (~20% of max_tokens)
    medium_max: 8192  # 5K-15K tokens: balanced tasks (~50% of max_tokens)
    # 15K+ tokens: high effort complex reasoning (up to 32K cap)

# Timeout configuration
timeouts_ms:
  connect: 5000    # 5 seconds
  read: 600000     # 10 minutes for long reasoning tasks

# Logging configuration
logging:
  level: "debug"

# Override rules for routing decisions
overrides:
  # Route any model containing "haiku" to background model (most general first)
  - when:
      request:
        model_contains: "haiku"
    model: "openai/gpt-5-mini"
    
  # Route any model containing "mini" to background model
  - when:
      request:
        model_contains: "mini"  
    model: "openai/gpt-5-mini"