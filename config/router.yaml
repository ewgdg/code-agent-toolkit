# Claude Code Model Router Configuration
# This configuration routes Claude Code CLI traffic to appropriate endpoints

router:
  listen: "0.0.0.0:8787"
  original_base_url: "https://api.anthropic.com"

# Provider configurations
providers:
  openai:
    base_url: "https://api.openai.com/v1"
    adapter: "openai-responses"
    api_key_env: "OPENAI_API_KEY"

# OpenAI configuration
openai:
  reasoning_effort_default: "minimal"  # Cost-efficient default
  reasoning_thresholds:
    low_max: 2048      # 1-5K tokens: simple tasks (~20% of max_tokens)
    medium_max: 8192  # 5K-15K tokens: balanced tasks (~50% of max_tokens)
    # 15K+ tokens: high effort complex reasoning (up to 32K cap)
  reasoning_model_prefixes:
    - "o"
    - "gpt-5"
    - "gpt-oss"

# Timeout configuration
timeouts_ms:
  connect: 10000    # 10 seconds
  read: 300000

# Logging configuration
logging:
  level: "info"

# Override rules for routing decisions
overrides:
  # Route plan mode requests to reasoning model
  - when:
      request:
        user_regex: '<system-reminder>[\s\S]*\b(?:plan mode is (?:activated|active|triggered|on)|in plan mode)\b[\s\S]*</system-reminder>'
    provider: "openai"
    model: "gpt-5"
    config:
      reasoning:
        effort: 
          value: "medium"
          priority: "default"
        summary: "auto"
    
  # Route opus model requests to powerful OpenAI model
  - when:
      request:
        model_regex: 'opus'
    provider: "openai"
    model: "gpt-5"
    
  # Route llama requests to local llama instance
  - when:
      request:
        model_regex: 'gpt-oss(?:-.*)?'
    provider: "llama"
    model: "gpt-oss"
    
  # Route any model containing "mini" to background model
  - when:
      request:
        model_regex: 'mini'
    provider: "openai"
    model: "gpt-5-mini"
  
  # Route specific model with reasoning configuration
  - when:
      request:
        model_regex: '^gpt-high$'
    model: "gpt-5"
    provider: "openai"
    config:
      reasoning:
        effort: 
          value: "high"
          priority: "always"  # Always use high effort for this model
        summary: "auto"
  
  # Route gpt requests to OpenAI
  - when:
      request:
        model_regex: '^gpt$'
    provider: "openai"
    model: "gpt-5"